{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARIES / BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries necessaries for this code\n",
    "# Bibliotecas necessárias para este código\n",
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from mage_ai.settings.repo import get_repo_path\n",
    "from mage_ai.io.bigquery import BigQuery\n",
    "from mage_ai.io.config import ConfigFileLoader\n",
    "from pandas import DataFrame\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT / EXTRAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data_loader decorator if not already imported\n",
    "# Importa o decorador data_loader se ainda não estiver importado\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "\n",
    "# Import the test decorator if not already imported\n",
    "# Importa o decorador test se ainda não estiver importado\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "@data_loader\n",
    "def load_data_from_api(*args, **kwargs):\n",
    "\n",
    "    # Define the URL of the data file\n",
    "    # Define a URL do arquivo de dados\n",
    "    url = 'https://storage.googleapis.com/trip-bucket/trip_data.parquet'\n",
    "    # Make an HTTP GET request to the URL\n",
    "    # Faz uma requisição HTTP GET para a URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Read the response content as a byte stream\n",
    "    # Lê o conteúdo da resposta como um fluxo de bytes\n",
    "    data = io.BytesIO(response.content)\n",
    "\n",
    "    # Load the data into a pandas DataFrame from the Parquet file\n",
    "    # Carrega os dados em um DataFrame do pandas a partir do arquivo Parquet\n",
    "    df_trip = pd.read_parquet(data)\n",
    "\n",
    "    # Return the loaded DataFrame\n",
    "    # Retorna o DataFrame carregado\n",
    "    return df_trip\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \n",
    "    # Check if the output is not None\n",
    "    # Verifica se a saída não é indefinida\n",
    "    assert output is not None, 'The output is undefined'\n",
    "    # Check if the output is not None \n",
    "    # Verifica se a saída não é indefinida \n",
    "    assert output is not None, 'A saída está indefinida'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORM / TRANSFORMAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the transformer decorator if not already imported\n",
    "# Importa o decorador transformer se ainda não estiver importado\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "\n",
    "# Import the test decorator if not already imported\n",
    "# Importa o decorador test se ainda não estiver importado\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "@transformer\n",
    "def transform(df_trip, *args, **kwargs):\n",
    "\n",
    "    # Dictionary for storing dataframes\n",
    "    # Dicionário para armazenamento dos dataframes\n",
    "    dataframes = {}\n",
    "\n",
    "    # Create a new global index and reset index\n",
    "    # Criação de novo índice global e redefinição do índice\n",
    "    df_trip = df_trip.drop_duplicates().reset_index(drop=True)\n",
    "    df_trip['trip_id'] = df_trip.index\n",
    "\n",
    "    # Create and configure datetime dimension table\n",
    "    # Criação e configuração da tabela de dimensão datetime\n",
    "    df_trip['lpep_pickup_datetime'] = pd.to_datetime(df_trip['lpep_pickup_datetime'])\n",
    "    df_trip['lpep_dropoff_datetime'] = pd.to_datetime(df_trip['lpep_dropoff_datetime'])\n",
    "    datetime_dim = df_trip[['lpep_pickup_datetime', 'lpep_dropoff_datetime']].reset_index()\n",
    "    datetime_dim['pick_hour'] = datetime_dim['lpep_pickup_datetime'].dt.hour\n",
    "    datetime_dim['pick_day'] = datetime_dim['lpep_pickup_datetime'].dt.day\n",
    "    datetime_dim['pick_month'] = datetime_dim['lpep_pickup_datetime'].dt.month\n",
    "    datetime_dim['pick_year'] = datetime_dim['lpep_pickup_datetime'].dt.year\n",
    "    datetime_dim['pick_weekday'] = datetime_dim['lpep_pickup_datetime'].dt.weekday\n",
    "    datetime_dim['drop_hour'] = datetime_dim['lpep_dropoff_datetime'].dt.hour\n",
    "    datetime_dim['drop_day'] = datetime_dim['lpep_dropoff_datetime'].dt.day\n",
    "    datetime_dim['drop_month'] = datetime_dim['lpep_dropoff_datetime'].dt.month\n",
    "    datetime_dim['drop_year'] = datetime_dim['lpep_dropoff_datetime'].dt.year\n",
    "    datetime_dim['drop_weekday'] = datetime_dim['lpep_dropoff_datetime'].dt.weekday\n",
    "    datetime_dim['datetime_id'] = datetime_dim.index\n",
    "    datetime_dim = datetime_dim[['datetime_id', 'lpep_pickup_datetime', 'pick_hour', 'pick_day', 'pick_month', 'pick_year', 'pick_weekday', 'lpep_dropoff_datetime', 'drop_hour', 'drop_day', 'drop_month', 'drop_year', 'drop_weekday']]\n",
    "    dataframes['datetime_dim'] = datetime_dim\n",
    "\n",
    "    # Create the distance dimension\n",
    "    # Criação da dimensão distância\n",
    "    distance_dim = df_trip[['trip_distance']].reset_index(drop=True)\n",
    "    distance_dim['distance_id'] = distance_dim.index\n",
    "    distance_dim = distance_dim[['distance_id', 'trip_distance']]\n",
    "    dataframes['distance_dim'] = distance_dim\n",
    "\n",
    "    # Create the rate code dimension\n",
    "    # Criação da dimensão rate_code\n",
    "    rate_code_name = {\n",
    "        1: \"Standard rate\",\n",
    "        2: \"JFK\",\n",
    "        3: \"Newark\",\n",
    "        4: \"Nessau or Westchester\",\n",
    "        5: \"Negotiated fare\",\n",
    "        6: \"Group ride\"\n",
    "    }\n",
    "    rate_code_dim = df_trip[['RatecodeID']].reset_index(drop=True)\n",
    "    rate_code_dim['rate_code_id'] = rate_code_dim.index\n",
    "    rate_code_dim['rate_code_name'] = rate_code_dim['RatecodeID'].map(rate_code_name)\n",
    "    rate_code_dim['rate_code_name'] = rate_code_dim['rate_code_name'].fillna('Unknown')\n",
    "    rate_code_dim = rate_code_dim[['rate_code_id', 'RatecodeID', 'rate_code_name']]\n",
    "    dataframes['rate_code_dim'] = rate_code_dim\n",
    "\n",
    "    # Create the trip type dimension\n",
    "    # Criação da dimensão tipo de viagem\n",
    "    trip_type_name = {\n",
    "        1: \"Street-hail\",\n",
    "        2: \"Dispatch\"\n",
    "    }\n",
    "    trip_type_dim = df_trip[['trip_type']].reset_index(drop=True)\n",
    "    trip_type_dim['trip_type_id'] = trip_type_dim.index\n",
    "    trip_type_dim['trip_type_name'] = trip_type_dim['trip_type'].map(trip_type_name)\n",
    "    trip_type_dim['trip_type_name'] = trip_type_dim['trip_type_name'].fillna('Unknown')\n",
    "    trip_type_dim = trip_type_dim[['trip_type_id', 'trip_type', 'trip_type_name']]\n",
    "    dataframes['trip_type_dim'] = trip_type_dim\n",
    "\n",
    "    # Create the pick-up location dimension\n",
    "    # Criação da dimensão local de coleta\n",
    "    pick_up_location_dim = df_trip[['PULocationID']].reset_index(drop=True)\n",
    "    pick_up_location_dim['pick_up_id'] = pick_up_location_dim.index\n",
    "    pick_up_location_dim = pick_up_location_dim[['pick_up_id', 'PULocationID']]\n",
    "    dataframes['pick_up_location_dim'] = pick_up_location_dim\n",
    "\n",
    "    # Create the drop-off location dimension\n",
    "    # Criação da dimensão local de entrega\n",
    "    drop_off_location_dim = df_trip[['DOLocationID']].reset_index(drop=True)\n",
    "    drop_off_location_dim['drop_off_id'] = drop_off_location_dim.index\n",
    "    drop_off_location_dim = drop_off_location_dim[['drop_off_id', 'DOLocationID']]\n",
    "    dataframes['drop_off_location_dim'] = drop_off_location_dim\n",
    "\n",
    "    # Create the payment type dimension\n",
    "    # Criação da dimensão tipo de pagamento\n",
    "    payment_type_name = {\n",
    "        1: \"Credit card\",\n",
    "        2: \"Cash\",\n",
    "        3: \"No charge\",\n",
    "        4: \"Dispute\",\n",
    "        5: \"Unknown\",\n",
    "        6: \"Voided trip\"\n",
    "    }\n",
    "    payment_type_dim = df_trip[['payment_type']].reset_index(drop=True)\n",
    "    payment_type_dim['payment_type_id'] = payment_type_dim.index\n",
    "    payment_type_dim['payment_type_name'] = payment_type_dim['payment_type'].map(payment_type_name)\n",
    "    payment_type_dim['payment_type_name'] = payment_type_dim['payment_type_name'].fillna('Unknown')\n",
    "    payment_type_dim = payment_type_dim[['payment_type_id', 'payment_type', 'payment_type_name']]\n",
    "    dataframes['payment_type_dim'] = payment_type_dim\n",
    "\n",
    "    # Create the fact table\n",
    "    # Criação da tabela fato\n",
    "    fact_table = df_trip.merge(datetime_dim, left_on='trip_id', right_on='datetime_id') \\\n",
    "                  .merge(distance_dim, left_on='trip_id', right_on='distance_id') \\\n",
    "                  .merge(rate_code_dim, left_on='trip_id', right_on='rate_code_id') \\\n",
    "                  .merge(trip_type_dim, left_on='trip_id', right_on='trip_type_id')  \\\n",
    "                  .merge(pick_up_location_dim, left_on='trip_id', right_on='pick_up_id') \\\n",
    "                  .merge(drop_off_location_dim, left_on='trip_id', right_on='drop_off_id') \\\n",
    "                  .merge(payment_type_dim, left_on='trip_id', right_on='payment_type_id') \\\n",
    "                  [['trip_id', 'VendorID', 'datetime_id', 'trip_type_id', 'rate_code_id', 'distance_id', 'pick_up_id', 'drop_off_id', 'payment_type_id', 'passenger_count', 'total_amount', 'fare_amount', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'congestion_surcharge', 'extra', 'store_and_fwd_flag']]\n",
    "    dataframes['fact_table'] = fact_table\n",
    "\n",
    "    # Return all dataframes as dictionaries\n",
    "    # Retorna todos os dataframes como dicionários\n",
    "    return {\n",
    "        \"datetime_dim\": datetime_dim.to_dict(orient=\"records\"),\n",
    "        \"distance_dim\": distance_dim.to_dict(orient=\"records\"),\n",
    "        \"rate_code_dim\": rate_code_dim.to_dict(orient=\"records\"),\n",
    "        \"trip_type_dim\": trip_type_dim.to_dict(orient=\"records\"),\n",
    "        \"pick_up_location_dim\": pick_up_location_dim.to_dict(orient=\"records\"),\n",
    "        \"drop_off_location_dim\": drop_off_location_dim.to_dict(orient=\"records\"),\n",
    "        \"payment_type_dim\": payment_type_dim.to_dict(orient=\"records\"),\n",
    "        \"fact_table\": fact_table.to_dict(orient=\"records\")\n",
    "    }\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "\n",
    "    assert output is not None, 'The output is undefined'\n",
    "    # Verify if the output it's not undefined\n",
    "    # Verifica se a saída não é indefinida\n",
    "    assert output is not None, 'A saída está indefinida'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD / CARREGAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data_exporter decorator if not already imported\n",
    "# Importa o decorador data_exporter se ainda não estiver importado\n",
    "if 'data_exporter' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_exporter\n",
    "\n",
    "@data_exporter\n",
    "def export_data_to_big_query(data, **kwargs) -> None:\n",
    "\n",
    "    # Define the path to the configuration file\n",
    "    # Define o caminho para o arquivo de configuração\n",
    "    config_path = path.join(get_repo_path(), 'io_config.yaml')\n",
    "    config_profile = 'default'  # Define the configuration profile to use\n",
    "    # Define o perfil de configuração a ser usado\n",
    "\n",
    "    # Iterate through each key-value pair in the data dictionary\n",
    "    # Itera por cada par chave-valor no dicionário de dados\n",
    "    for key, values in data.items():\n",
    "        # Construct the BigQuery table ID using the key\n",
    "        # Construa o ID da tabela BigQuery usando a chave\n",
    "        table_id = f'trip-project-432523.trip_project_dataset.{key}'\n",
    "        \n",
    "        # Export the data to BigQuery using the specified configuration\n",
    "        # Exporte os dados para o BigQuery usando a configuração especificada\n",
    "        BigQuery.with_config(ConfigFileLoader(config_path, config_profile)).export(\n",
    "            DataFrame(values),\n",
    "            table_id,\n",
    "            if_exists='replace',  # Specify resolution policy if table name already exists\n",
    "            # Especificar política de resolução se o nome da tabela já existir\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
